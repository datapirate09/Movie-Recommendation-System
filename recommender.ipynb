{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945e6e3-3762-4c4d-b5a3-9018cc6cbbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title\n",
      "0        1                    Toy Story (1995)\n",
      "1        2                      Jumanji (1995)\n",
      "2        3             Grumpier Old Men (1995)\n",
      "3        4            Waiting to Exhale (1995)\n",
      "4        5  Father of the Bride Part II (1995)\n",
      "   userId  movieId  rating\n",
      "0       1        1     4.0\n",
      "1       1        3     4.0\n",
      "2       1        6     4.0\n",
      "3       1       47     5.0\n",
      "4       1       50     5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "movies_dataset = pd.read_csv(\"movies.csv\")\n",
    "rating_dataset = pd.read_csv(\"ratings.csv\")\n",
    "columns_movies_dataset = [\"movieId\", \"title\"]\n",
    "columns_rating_dataset = [\"userId\", \"movieId\", \"rating\"]\n",
    "movies_dataset_cleaned = movies_dataset[columns_movies_dataset]\n",
    "rating_dataset_cleaned = rating_dataset[columns_rating_dataset]\n",
    "print(movies_dataset_cleaned.head())\n",
    "print(rating_dataset_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a2297c2-2600-4b70-a8c3-55410f626afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "9724\n"
     ]
    }
   ],
   "source": [
    "no_of_users = rating_dataset_cleaned['userId'].unique().shape[0]\n",
    "print(no_of_users)\n",
    "#find movies without any user giving rating and remove them\n",
    "movies_rated = set(rating_dataset_cleaned['movieId'].unique())\n",
    "total_movies = movies_dataset_cleaned['movieId']\n",
    "movies_unrated = [movie for movie in total_movies if movie not in movies_rated]\n",
    "#remove movies_unrated from movies_dataset_cleaned\n",
    "movies_dataset_refined = movies_dataset_cleaned[~movies_dataset_cleaned['movieId'].isin(movies_unrated)]\n",
    "movies_dataset_refined.to_csv(\"refined_movies.csv\")\n",
    "no_of_movies = movies_dataset_refined['movieId'].shape[0]\n",
    "print(no_of_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b36da62-b7fb-4946-885f-26323528a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userId  movieId  rating  movieIndex\n",
      "0        1        1     4.0           0\n",
      "1        1        3     4.0           2\n",
      "2        1        6     4.0           5\n",
      "3        1       47     5.0          43\n",
      "4        1       50     5.0          46\n",
      "5        1       70     3.0          62\n",
      "6        1      101     5.0          89\n",
      "7        1      110     4.0          97\n",
      "8        1      151     5.0         124\n",
      "9        1      157     5.0         130\n",
      "10       1      163     5.0         136\n",
      "11       1      216     5.0         184\n",
      "12       1      223     3.0         190\n",
      "13       1      231     5.0         197\n",
      "14       1      235     4.0         201\n",
      "15       1      260     5.0         224\n",
      "16       1      296     3.0         257\n",
      "17       1      316     3.0         275\n",
      "18       1      333     5.0         291\n",
      "19       1      349     4.0         307\n",
      "20       1      356     4.0         314\n",
      "21       1      362     5.0         320\n",
      "22       1      367     4.0         325\n",
      "23       1      423     3.0         367\n",
      "24       1      441     4.0         384\n",
      "25       1      457     5.0         398\n",
      "26       1      480     4.0         418\n",
      "27       1      500     3.0         436\n",
      "28       1      527     5.0         461\n",
      "29       1      543     4.0         476\n"
     ]
    }
   ],
   "source": [
    "movies_dataset_refined = pd.read_csv(\"refined_movies_final.csv\")\n",
    "movies_dataset_refined = movies_dataset_refined.reset_index(drop=True)\n",
    "movies_dataset_refined[\"movieIndex\"] = movies_dataset_refined.index\n",
    "movies_dataset_refined.to_csv(\"final_movies_dataset.csv\", index=False)\n",
    "movie_id_to_index = dict(zip(movies_dataset_refined[\"movieId\"], movies_dataset_refined[\"movieIndex\"]))\n",
    "rating_dataset_cleaned[\"movieIndex\"] = rating_dataset_cleaned[\"movieId\"].apply(lambda x:movie_id_to_index[x])\n",
    "print(rating_dataset_cleaned.iloc[:30,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9487928-f582-44fd-a2b4-3789a4d00b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.  0.  0.  0.  4.  0.  4.5 0.  0.  0.  0.  0.  0.  0.  2.5 0.  4.5 3.5\n",
      " 4.  0.  3.5 0.  0.  0.  0.  0.  3.  0.  0.  0.  5.  3.  3.  0.  0.  0.\n",
      " 0.  0.  0.  5.  0.  0.  5.  3.  4.  5.  0.  0.  0.  3.  0.  0.  0.  3.\n",
      " 0.  0.  5.  0.  0.  0.  0.  0.  5.  4.  0.  4.  0.  2.5 0.  0.  5.  0.\n",
      " 4.5 0.  0.  0.5 0.  4.  0.  0.  0.  2.5 0.  0.  0.  4.  0.  0.  3.  3.\n",
      " 4.  0.  3.  0.  0.  5.  0.  4.5 0.  0.  0.  0.  4.  0.  0.  0.  4.  0.\n",
      " 0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  3.5 0.  4.  0.  0.  4.  0.  0.\n",
      " 0.  0.  0.  3.  0.  2.  0.  3.  4.  0.  4.  0.  0.  3.  4.  0.  0.  3.5\n",
      " 5.  0.  0.  0.  0.  0.  5.  0.  2.  0.  3.  4.  0.  0.  4.5 4.  4.  0.\n",
      " 0.  0.  0.  5.  3.5 0.  4.5 0.  5.  0.  0.  0.  0.  0.  5.  4.  4.  0.\n",
      " 0.  4.  0.  0.  4.  4.  0.  0.  0.  0.  4.  0.  2.  0.  0.  0.  0.  0.\n",
      " 0.  3.5 5.  4.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  3.5 3.  0.  3.\n",
      " 4.  0.  3.5 5.  0.  0.  3.5 0.  0.  3.5 0.  0.  5.  0.  0.  3.5 3.  5.\n",
      " 0.  0.  0.  0.  4.  5.  0.  0.  0.  0.  0.  0.  5.  0.  4.  0.  0.  4.5\n",
      " 0.  4.5 0.  0.  0.  0.  0.  0.  0.  0.  4.  4.  0.  2.  0.  0.  5.  5.\n",
      " 0.  0.  5.  4.  5.  4.  4.  0.  3.  4.5 0.  4.5 3.  0.  0.  0.  0.  4.5\n",
      " 0.  4.  4.  4.  3.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  5.  0.  0.\n",
      " 4.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  3.5 3.5 0.\n",
      " 0.  0.  0.  5.  0.  4.  0.  4.  0.  3.5 0.  4.  4.  0.  4.  0.  5.  0.\n",
      " 0.  0.  0.  0.  5.  0.  0.  4.  0.  0.  5.  0.  0.  0.  5.  0.  4.  0.\n",
      " 0.  0.  0.  5.  0.  0.  5.  0.  0.  0.  0.  3.  3.  0.  0.  0.  0.  4.5\n",
      " 0.  5.  3.5 4.5 0.  0.  4.  0.  0.  0.  5.  0.  3.  0.  0.  0.  0.  5.\n",
      " 0.  0.  4.  0.  3.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  2.  0.  4.\n",
      " 0.  0.  0.  0.  0.  4.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.5\n",
      " 0.  4.  0.  4.  0.  4.5 0.  0.  0.  0.  4.  0.  0.  0.  0.  5.  0.  0.\n",
      " 5.  0.  5.  0.  0.  5.  0.  0.  0.  4.5 0.  1.5 0.  0.  0.  0.  0.  4.\n",
      " 4.  4.  5.  0.  0.  4.  0.  4.  4.  0.  0.  3.  0.  0.  4.  4.5 0.  0.\n",
      " 0.  4.5 0.  3.5 0.  4.  0.  0.  0.  0.  0.  0.  0.  4.  0.  0.  0.  4.\n",
      " 0.  0.  0.  0.  4.  0.  0.  0.  0.  4.  0.  0.  4.  0.  0.  0.  0.  3.\n",
      " 0.  4.  4.  0.  0.  2.5 3.  0.  0.  0.  5.  4.  0.  0.  0.  0.  0.  0.\n",
      " 3.  0.  0.  3.  0.  0.  0.  0.  0.  4.  0.  0.  0.  0.  4.  0.  0.  0.\n",
      " 5.  3.  4.  4.5 0.  0.  0.  0.  3.5 0.  0.  4.  0.  4.  5.  0.  0.  0.\n",
      " 0.  0.  4.  3.  0.  0.  0.  5.  0.  0.  5.  0.  0.  4.  0.  0.  0.  0.\n",
      " 0.  4.  4.  0.  3.  2.5 4.  0.  4.  3.  4.  2.5 4.  2.5 3.  5. ]\n"
     ]
    }
   ],
   "source": [
    "#we need to form 2 2-d arrays. one is output rating array and one is array R where Rij = 1 if rating is there else Rij = 0\n",
    "y_actual = np.zeros((no_of_movies,no_of_users))\n",
    "rating_array = np.zeros((no_of_movies,no_of_users))\n",
    "for index,row in rating_dataset_cleaned.iterrows():\n",
    "    movie_index = int(row['movieIndex'])\n",
    "    user_index = int(row['userId']) - 1\n",
    "    rating_array[movie_index,user_index] = 1\n",
    "    y_actual[movie_index,user_index] = row['rating']\n",
    "print(y_actual[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "926f7d24-465d-45b4-94e4-76e82599444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape is  (9724, 610)\n",
      "R shape is  (9724, 610)\n",
      "w shape is  (611, 20)\n",
      "X shape is  (9724, 20)\n"
     ]
    }
   ],
   "source": [
    "#we have our output values ready\n",
    "# now we need our X and w matrices. X matrix shape should be no_of_movies x features and w should be no_of_users x features so when x and wt are\n",
    "# multiplied we get y as no_of_movies x no_of_users which is our y. lets take 10 features\n",
    "# w = np.random.randn(no_of_users+1, 10) * 0.01\n",
    "# X = np.random.randn(no_of_movies,10) * 0.01\n",
    "# b = np.zeros((no_of_movies, 1))\n",
    "\n",
    "w = tf.Variable(np.random.randn(no_of_users + 1, 20) * 0.01, dtype=tf.float32)\n",
    "X = tf.Variable(np.random.randn(no_of_movies, 20) * 0.01, dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((no_of_movies, 1)), dtype=tf.float32)\n",
    "\n",
    "#lets print all shapes to verify if we are correct\n",
    "print(\"Y shape is \", y_actual.shape)\n",
    "print(\"R shape is \", rating_array.shape)\n",
    "print(\"w shape is \", w.shape)\n",
    "print(\"X shape is \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6ae8008-aabb-418a-a16f-3cb38e9094a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cost(X, W, b, Y, R, lambda_):\n",
    "#     y_pred = X @ W.T + b  \n",
    "#     error = (y_pred - Y) * R \n",
    "#     J = 0.5 * np.sum(error ** 2) \n",
    "#     J += 0.5 * lambda_ * (np.sum(W ** 2) + np.sum(X ** 2))\n",
    "#     return J\n",
    "\n",
    "def compute_cost(X, W, b, Y, R, lambda_):\n",
    "    y_pred = tf.matmul(X, tf.transpose(W)) + b\n",
    "    error = (y_pred - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(tf.square(error))\n",
    "    J += 0.5 * lambda_ * (tf.reduce_sum(tf.square(W)) + tf.reduce_sum(tf.square(X)))\n",
    "    return J  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dd6a7af-f392-4990-868f-7f8ce78afe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3688 6298 1982 1158 4356 6732 7026 4413 4112 6611 1681 1706 3715 2975\n",
      " 4597 4809 8714 3738 8300 3191 7992 5022 6479 5860 5767 5344 8567 6554\n",
      " 2693  341]\n",
      "      movieId                                              title  movieIndex\n",
      "3688     5093                           Collateral Damage (2002)        3688\n",
      "6298    48516                               Departed, The (2006)        6298\n",
      "1982     2633                                  Mummy, The (1932)        1982\n",
      "1158     1529                                     Nowhere (1997)        1158\n",
      "4356     6379                                  Wrong Turn (2003)        4356\n",
      "6732    59429  American Pie Presents Beta House (American Pie...        6732\n",
      "7026    69122                               Hangover, The (2009)        7026\n",
      "4413     6528             Start the Revolution Without Me (1970)        4413\n",
      "4112     5903                                 Equilibrium (2002)        4112\n",
      "6611    56169                                       Awake (2007)        6611\n",
      "1681     2263                           Seventh Sign, The (1988)        1681\n",
      "1706     2295                              Impostors, The (1998)        1706\n",
      "3715     5139                         Bad News Bears, The (1976)        3715\n",
      "2975     3991                              102 Dalmatians (2000)        2975\n",
      "4597     6858           Knife in the Water (Nóz w wodzie) (1962)        4597\n",
      "4809     7178                           Great Gatsby, The (1974)        4809\n",
      "8714   127116                                Experimenter (2015)        8714\n",
      "3738     5213                            Oh, God! Book II (1980)        3738\n",
      "8300   107159  Zatoichi and the Chest of Gold (Zatôichi senry...        8300\n",
      "3191     4308                                Moulin Rouge (2001)        3191\n",
      "7992    97665  Asterix & Obelix: God Save Britannia (Astérix ...        7992\n",
      "5022     7834                          After the Thin Man (1936)        5022\n",
      "6479    53318                                    Cashback (2006)        6479\n",
      "5860    33126                             Frisco Kid, The (1979)        5860\n",
      "5767    31433                           Wedding Date, The (2005)        5767\n",
      "5344     8928               Fearless Vampire Killers, The (1967)        5344\n",
      "8567   117364                                     Virunga (2014)        8567\n",
      "6554    55118                            Eastern Promises (2007)        6554\n",
      "2693     3618                           Small Time Crooks (2000)        2693\n",
      "341       384                                 Bad Company (1995)         341\n"
     ]
    }
   ],
   "source": [
    "#now lets add our ratings. we need to increase no of users by 1 which indicate us\n",
    "random_movies_indices = np.random.choice(no_of_movies, 30, replace=False)\n",
    "print(random_movies_indices)\n",
    "random_movies_selected = movies_dataset_refined.loc[random_movies_indices,:]\n",
    "print(random_movies_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd6e43c7-9ef5-487c-bb40-c5e3a6b28ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(no_of_movies)\n",
    "# random_ratings = np.random.randint(1,5,30)\n",
    "# for i, (_, movie) in enumerate(random_movies_selected.iterrows()):\n",
    "#     movie_index = movie['movieIndex']\n",
    "#     my_ratings[movie_index] = random_ratings[i]\n",
    "my_ratings[1] = 4\n",
    "my_ratings[6182] = 3\n",
    "my_ratings[6191] = 4\n",
    "my_ratings[6234] = 3.5\n",
    "my_ratings[6241] = 4.5\n",
    "my_ratings[6248] = 4\n",
    "my_ratings[6299] = 3.5\n",
    "my_ratings[6314] = 4.5\n",
    "my_ratings[6364] = 2.5\n",
    "my_ratings[6450] = 3.5\n",
    "my_ratings[6693] = 5\n",
    "my_ratings[6729] = 3.5\n",
    "my_ratings[6736] = 4.5\n",
    "my_ratings[6743] = 4\n",
    "my_ratings[6975] = 2.5\n",
    "my_ratings[7069] = 3\n",
    "my_ratings[7114] = 3.5\n",
    "my_ratings[7226] = 5\n",
    "my_ratings[7241] = 4.5\n",
    "my_ratings[7305] = 1.5\n",
    "my_ratings[7396] = 3.5\n",
    "my_ratings[7637] = 4.5\n",
    "my_ratings[7650] = 2.5\n",
    "my_ratings[7707] = 3.5\n",
    "my_ratings[7750] = 3\n",
    "my_ratings[7756] = 2.5\n",
    "my_ratings[7827] = 3.5\n",
    "my_ratings[7937] = 2.5\n",
    "my_ratings[8008] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "461473fb-5308-46c5-8a22-1f461878f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 611)\n"
     ]
    }
   ],
   "source": [
    "y_actual = np.c_[my_ratings, y_actual]\n",
    "print(y_actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbe99f0f-d7da-44fa-95d4-52cacd215eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 611)\n"
     ]
    }
   ],
   "source": [
    "my_rating_exists_array = (my_ratings > 0).astype(int)\n",
    "rating_array = np.c_[my_rating_exists_array,rating_array]\n",
    "print(rating_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d98ef-98a3-40e8-ba30-4e0dc7627ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b87249a-32c4-4ce4-8756-06a2723fc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the rating by calc mean rating for every movie\n",
    "def normalize_function(Y,R):\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return Ynorm, Ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5af11ab8-9c9b-4d51-bb80-23166616d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual_normalized, y_mean = normalize_function(y_actual,rating_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8b19690-46fa-4b8a-86e3-eea896098730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 38714.7031\n",
      "Training loss at iteration 20: 37264.7891\n",
      "Training loss at iteration 40: 31005.8926\n",
      "Training loss at iteration 60: 24461.7656\n",
      "Training loss at iteration 80: 18670.5234\n",
      "Training loss at iteration 100: 14346.0527\n",
      "Training loss at iteration 120: 11510.0635\n",
      "Training loss at iteration 140: 9747.6113\n",
      "Training loss at iteration 160: 8622.5098\n",
      "Training loss at iteration 180: 7864.7993\n",
      "Training loss at iteration 200: 7333.6455\n",
      "Training loss at iteration 220: 6946.8159\n",
      "Training loss at iteration 240: 6655.7451\n",
      "Training loss at iteration 260: 6430.3003\n",
      "Training loss at iteration 280: 6251.7139\n",
      "Training loss at iteration 300: 6107.3638\n",
      "Training loss at iteration 320: 5988.5063\n",
      "Training loss at iteration 340: 5889.0679\n",
      "Training loss at iteration 360: 5804.7769\n",
      "Training loss at iteration 380: 5732.4380\n",
      "Training loss at iteration 400: 5669.7417\n",
      "Training loss at iteration 420: 5614.8936\n",
      "Training loss at iteration 440: 5566.4858\n",
      "Training loss at iteration 460: 5523.4067\n",
      "Training loss at iteration 480: 5484.7681\n",
      "Training loss at iteration 500: 5449.8711\n",
      "Training loss at iteration 520: 5418.1611\n",
      "Training loss at iteration 540: 5389.1675\n",
      "Training loss at iteration 560: 5362.5137\n",
      "Training loss at iteration 580: 5337.8901\n",
      "Training loss at iteration 600: 5315.0381\n",
      "Training loss at iteration 620: 5293.7573\n",
      "Training loss at iteration 640: 5273.8545\n",
      "Training loss at iteration 660: 5255.1924\n",
      "Training loss at iteration 680: 5237.6328\n",
      "Training loss at iteration 700: 5221.0688\n",
      "Training loss at iteration 720: 5205.4170\n",
      "Training loss at iteration 740: 5190.5952\n",
      "Training loss at iteration 760: 5176.5410\n",
      "Training loss at iteration 780: 5163.1904\n",
      "Training loss at iteration 800: 5150.4995\n",
      "Training loss at iteration 820: 5138.4229\n",
      "Training loss at iteration 840: 5126.9180\n",
      "Training loss at iteration 860: 5115.9561\n",
      "Training loss at iteration 880: 5105.4961\n",
      "Training loss at iteration 900: 5095.5117\n",
      "Training loss at iteration 920: 5085.9717\n",
      "Training loss at iteration 940: 5076.8491\n",
      "Training loss at iteration 960: 5068.1216\n",
      "Training loss at iteration 980: 5059.7607\n"
     ]
    }
   ],
   "source": [
    "# iterations = 1500\n",
    "# lambda_ = 0.1\n",
    "# learning_rate = 0.01\n",
    "# for iter in range(iterations):\n",
    "#     print(iter)\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         cost_value = compute_cost(X, w, b, y_actual_normalized, rating_array, lambda_)\n",
    "#     grads = tape.gradient( cost_value, [X,w,b] )\n",
    "#     dX, dW, db = grads\n",
    "#     X.assign_sub(learning_rate * dX)\n",
    "#     w.assign_sub(learning_rate * dW)\n",
    "#     b.assign_sub(learning_rate * db)\n",
    "#     if iter % 20 == 0:\n",
    "#         print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "iterations = 1000   \n",
    "lambda_ = 0.05      \n",
    "learning_rate = 0.01  \n",
    "min_delta = 1e-5  \n",
    "previous_loss = float('inf')\n",
    "\n",
    "for iter in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = compute_cost(X, w, b, y_actual_normalized, rating_array, lambda_)\n",
    "\n",
    "    grads = tape.gradient(cost_value, [X, w, b])    \n",
    "    grads = [tf.clip_by_value(g, -0.5, 0.5) for g in grads]  \n",
    "    dX, dW, db = grads\n",
    "    X.assign_sub(learning_rate * dX)\n",
    "    w.assign_sub(learning_rate * dW)\n",
    "    b.assign_sub(learning_rate * db)\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value.numpy():.4f}\")    \n",
    "    if abs(previous_loss - cost_value.numpy()) < min_delta:\n",
    "        print(f\"Stopping early at iteration {iter}. Loss stabilized at {cost_value.numpy():.4f}\")\n",
    "        break\n",
    "\n",
    "    previous_loss = cost_value.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf0e5415-fc54-48e1-9cd4-80c3b3bc8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the last user:\n",
      "1.9117352\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.matmul(X, tf.transpose(w)) + b \n",
    "y_pred_array = y_pred.numpy()\n",
    "y_pred_array += y_mean\n",
    "print(\"Predictions for the last user:\")\n",
    "print(y_pred_array[52,0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "694155cd-47a6-4b4e-a8e5-66fc7b9a9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs Predicted Ratings:\n",
      "(9724, 611)\n",
      "Movie Index 1: Actual = 4.0, Predicted = 3.93\n",
      "Movie Index 6182: Actual = 3.0, Predicted = 3.08\n",
      "Movie Index 6191: Actual = 4.0, Predicted = 3.97\n",
      "Movie Index 6234: Actual = 3.5, Predicted = 3.48\n",
      "Movie Index 6241: Actual = 4.5, Predicted = 4.53\n",
      "Movie Index 6248: Actual = 4.0, Predicted = 4.00\n",
      "Movie Index 6299: Actual = 3.5, Predicted = 3.50\n",
      "Movie Index 6314: Actual = 4.5, Predicted = 4.40\n",
      "Movie Index 6364: Actual = 2.5, Predicted = 2.50\n",
      "Movie Index 6450: Actual = 3.5, Predicted = 3.50\n",
      "Movie Index 6693: Actual = 5.0, Predicted = 4.85\n",
      "Movie Index 6729: Actual = 3.5, Predicted = 3.49\n",
      "Movie Index 6736: Actual = 4.5, Predicted = 4.49\n",
      "Movie Index 6743: Actual = 4.0, Predicted = 4.03\n",
      "Movie Index 6975: Actual = 2.5, Predicted = 2.51\n",
      "Movie Index 7069: Actual = 3.0, Predicted = 3.00\n",
      "Movie Index 7114: Actual = 3.5, Predicted = 3.49\n",
      "Movie Index 7226: Actual = 5.0, Predicted = 5.00\n",
      "Movie Index 7241: Actual = 4.5, Predicted = 4.41\n",
      "Movie Index 7305: Actual = 1.5, Predicted = 1.49\n",
      "Movie Index 7396: Actual = 3.5, Predicted = 3.43\n",
      "Movie Index 7637: Actual = 4.5, Predicted = 4.45\n",
      "Movie Index 7650: Actual = 2.5, Predicted = 2.51\n",
      "Movie Index 7707: Actual = 3.5, Predicted = 3.50\n",
      "Movie Index 7750: Actual = 3.0, Predicted = 3.17\n",
      "Movie Index 7756: Actual = 2.5, Predicted = 2.51\n",
      "Movie Index 7827: Actual = 3.5, Predicted = 3.56\n",
      "Movie Index 7937: Actual = 2.5, Predicted = 2.56\n",
      "Movie Index 8008: Actual = 3.0, Predicted = 3.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual vs Predicted Ratings:\")\n",
    "print(y_pred_array.shape)\n",
    "for i, rating in enumerate(my_ratings):\n",
    "    if rating > 0:\n",
    "        print(f\"Movie Index {i}: Actual = {rating}, Predicted = {y_pred_array[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8085305e-4e6b-4d83-ad84-2e075ecc949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar users: [(318, 0.6792879), (227, 0.6421401), (125, 0.62869483), (274, 0.5592607), (363, 0.5578882)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def find_similar_users(w, top_k=5):\n",
    "    user_vec = w[0]\n",
    "    \n",
    "    w_norm = tf.nn.l2_normalize(w, axis=1)\n",
    "    user_vec_norm = tf.nn.l2_normalize(user_vec, axis=0)\n",
    "    \n",
    "    similarity = tf.linalg.matmul(w_norm, tf.expand_dims(user_vec_norm, 1))\n",
    "    similarity = tf.squeeze(similarity)\n",
    "\n",
    "    similar_users = tf.argsort(similarity, direction='DESCENDING').numpy()\n",
    "    similar_users = [i for i in similar_users if i != 0][:top_k]\n",
    "\n",
    "    scores = similarity.numpy()[similar_users]\n",
    "    return list(zip(similar_users, scores))\n",
    "\n",
    "similar_users = find_similar_users(w, top_k=5)\n",
    "print(\"Top similar users:\", similar_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71b6dd5d-7511-41d6-b432-8958f8ad0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar users using KNN: [(318, 0.6792879), (227, 0.64214003), (125, 0.6286947), (274, 0.5592607), (363, 0.5578882)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_similar_users_knn(w, top_k=5):\n",
    "    w_np = w.numpy() \n",
    "    user_vec = w_np[0].reshape(1, -1)\n",
    "    \n",
    "    knn = NearestNeighbors(n_neighbors=top_k+1, metric=\"cosine\")\n",
    "    knn.fit(w_np)\n",
    "\n",
    "    distances, indices = knn.kneighbors(user_vec)\n",
    "    similar_users = indices[0][1:]\n",
    "    similarity_scores = 1 - distances[0][1:]\n",
    "\n",
    "    return list(zip(similar_users, similarity_scores))\n",
    "\n",
    "similar_users_knn = find_similar_users_knn(w, top_k=5)\n",
    "print(\"Top similar users using KNN:\", similar_users_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942e831-6c02-4e57-a8ec-354d9a1a8959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
