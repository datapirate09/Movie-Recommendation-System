{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2945e6e3-3762-4c4d-b5a3-9018cc6cbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title\n",
      "0        1                    Toy Story (1995)\n",
      "1        2                      Jumanji (1995)\n",
      "2        3             Grumpier Old Men (1995)\n",
      "3        4            Waiting to Exhale (1995)\n",
      "4        5  Father of the Bride Part II (1995)\n",
      "   userId  movieId  rating\n",
      "0       1        1     4.0\n",
      "1       1        3     4.0\n",
      "2       1        6     4.0\n",
      "3       1       47     5.0\n",
      "4       1       50     5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "movies_dataset = pd.read_csv(\"C:/Users/srina/OneDrive/Documents/ML Practice/Recommender System/movies.csv\")\n",
    "rating_dataset = pd.read_csv(\"C:/Users/srina/OneDrive/Documents/ML Practice/Recommender System/ratings.csv\")\n",
    "columns_movies_dataset = [\"movieId\", \"title\"]\n",
    "columns_rating_dataset = [\"userId\", \"movieId\", \"rating\"]\n",
    "movies_dataset_cleaned = movies_dataset[columns_movies_dataset]\n",
    "rating_dataset_cleaned = rating_dataset[columns_rating_dataset]\n",
    "print(movies_dataset_cleaned.head())\n",
    "print(rating_dataset_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3a2297c2-2600-4b70-a8c3-55410f626afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "9724\n"
     ]
    }
   ],
   "source": [
    "no_of_users = rating_dataset_cleaned['userId'].unique().shape[0]\n",
    "print(no_of_users)\n",
    "#find movies without any user giving rating and remove them\n",
    "movies_rated = set(rating_dataset_cleaned['movieId'].unique())\n",
    "total_movies = movies_dataset_cleaned['movieId']\n",
    "movies_unrated = [movie for movie in total_movies if movie not in movies_rated]\n",
    "#remove movies_unrated from movies_dataset_cleaned\n",
    "movies_dataset_refined = movies_dataset_cleaned[~movies_dataset_cleaned['movieId'].isin(movies_unrated)]\n",
    "movies_dataset_refined.to_csv(\"refined_movies.csv\")\n",
    "no_of_movies = movies_dataset_refined['movieId'].shape[0]\n",
    "print(no_of_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5b36da62-b7fb-4946-885f-26323528a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userId  movieId  rating  movieIndex\n",
      "0        1        1     4.0           0\n",
      "1        1        3     4.0           2\n",
      "2        1        6     4.0           5\n",
      "3        1       47     5.0          43\n",
      "4        1       50     5.0          46\n",
      "5        1       70     3.0          62\n",
      "6        1      101     5.0          89\n",
      "7        1      110     4.0          97\n",
      "8        1      151     5.0         124\n",
      "9        1      157     5.0         130\n",
      "10       1      163     5.0         136\n",
      "11       1      216     5.0         184\n",
      "12       1      223     3.0         190\n",
      "13       1      231     5.0         197\n",
      "14       1      235     4.0         201\n",
      "15       1      260     5.0         224\n",
      "16       1      296     3.0         257\n",
      "17       1      316     3.0         275\n",
      "18       1      333     5.0         291\n",
      "19       1      349     4.0         307\n",
      "20       1      356     4.0         314\n",
      "21       1      362     5.0         320\n",
      "22       1      367     4.0         325\n",
      "23       1      423     3.0         367\n",
      "24       1      441     4.0         384\n",
      "25       1      457     5.0         398\n",
      "26       1      480     4.0         418\n",
      "27       1      500     3.0         436\n",
      "28       1      527     5.0         461\n",
      "29       1      543     4.0         476\n"
     ]
    }
   ],
   "source": [
    "movies_dataset_refined = pd.read_csv(\"refined_movies_final.csv\")\n",
    "movies_dataset_refined = movies_dataset_refined.reset_index(drop=True)\n",
    "movies_dataset_refined[\"movieIndex\"] = movies_dataset_refined.index\n",
    "movies_dataset_refined.to_csv(\"final_movies_dataset.csv\", index=False)\n",
    "movie_id_to_index = dict(zip(movies_dataset_refined[\"movieId\"], movies_dataset_refined[\"movieIndex\"]))\n",
    "rating_dataset_cleaned[\"movieIndex\"] = rating_dataset_cleaned[\"movieId\"].map(movie_id_to_index)\n",
    "print(rating_dataset_cleaned.iloc[:30,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f9487928-f582-44fd-a2b4-3789a4d00b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.  0.  0.  0.  4.  0.  4.5 0.  0.  0.  0.  0.  0.  0.  2.5 0.  4.5 3.5\n",
      " 4.  0.  3.5 0.  0.  0.  0.  0.  3.  0.  0.  0.  5.  3.  3.  0.  0.  0.\n",
      " 0.  0.  0.  5.  0.  0.  5.  3.  4.  5.  0.  0.  0.  3.  0.  0.  0.  3.\n",
      " 0.  0.  5.  0.  0.  0.  0.  0.  5.  4.  0.  4.  0.  2.5 0.  0.  5.  0.\n",
      " 4.5 0.  0.  0.5 0.  4.  0.  0.  0.  2.5 0.  0.  0.  4.  0.  0.  3.  3.\n",
      " 4.  0.  3.  0.  0.  5.  0.  4.5 0.  0.  0.  0.  4.  0.  0.  0.  4.  0.\n",
      " 0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  3.5 0.  4.  0.  0.  4.  0.  0.\n",
      " 0.  0.  0.  3.  0.  2.  0.  3.  4.  0.  4.  0.  0.  3.  4.  0.  0.  3.5\n",
      " 5.  0.  0.  0.  0.  0.  5.  0.  2.  0.  3.  4.  0.  0.  4.5 4.  4.  0.\n",
      " 0.  0.  0.  5.  3.5 0.  4.5 0.  5.  0.  0.  0.  0.  0.  5.  4.  4.  0.\n",
      " 0.  4.  0.  0.  4.  4.  0.  0.  0.  0.  4.  0.  2.  0.  0.  0.  0.  0.\n",
      " 0.  3.5 5.  4.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  3.5 3.  0.  3.\n",
      " 4.  0.  3.5 5.  0.  0.  3.5 0.  0.  3.5 0.  0.  5.  0.  0.  3.5 3.  5.\n",
      " 0.  0.  0.  0.  4.  5.  0.  0.  0.  0.  0.  0.  5.  0.  4.  0.  0.  4.5\n",
      " 0.  4.5 0.  0.  0.  0.  0.  0.  0.  0.  4.  4.  0.  2.  0.  0.  5.  5.\n",
      " 0.  0.  5.  4.  5.  4.  4.  0.  3.  4.5 0.  4.5 3.  0.  0.  0.  0.  4.5\n",
      " 0.  4.  4.  4.  3.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.  5.  0.  0.\n",
      " 4.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  3.5 3.5 0.\n",
      " 0.  0.  0.  5.  0.  4.  0.  4.  0.  3.5 0.  4.  4.  0.  4.  0.  5.  0.\n",
      " 0.  0.  0.  0.  5.  0.  0.  4.  0.  0.  5.  0.  0.  0.  5.  0.  4.  0.\n",
      " 0.  0.  0.  5.  0.  0.  5.  0.  0.  0.  0.  3.  3.  0.  0.  0.  0.  4.5\n",
      " 0.  5.  3.5 4.5 0.  0.  4.  0.  0.  0.  5.  0.  3.  0.  0.  0.  0.  5.\n",
      " 0.  0.  4.  0.  3.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  2.  0.  4.\n",
      " 0.  0.  0.  0.  0.  4.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.5\n",
      " 0.  4.  0.  4.  0.  4.5 0.  0.  0.  0.  4.  0.  0.  0.  0.  5.  0.  0.\n",
      " 5.  0.  5.  0.  0.  5.  0.  0.  0.  4.5 0.  1.5 0.  0.  0.  0.  0.  4.\n",
      " 4.  4.  5.  0.  0.  4.  0.  4.  4.  0.  0.  3.  0.  0.  4.  4.5 0.  0.\n",
      " 0.  4.5 0.  3.5 0.  4.  0.  0.  0.  0.  0.  0.  0.  4.  0.  0.  0.  4.\n",
      " 0.  0.  0.  0.  4.  0.  0.  0.  0.  4.  0.  0.  4.  0.  0.  0.  0.  3.\n",
      " 0.  4.  4.  0.  0.  2.5 3.  0.  0.  0.  5.  4.  0.  0.  0.  0.  0.  0.\n",
      " 3.  0.  0.  3.  0.  0.  0.  0.  0.  4.  0.  0.  0.  0.  4.  0.  0.  0.\n",
      " 5.  3.  4.  4.5 0.  0.  0.  0.  3.5 0.  0.  4.  0.  4.  5.  0.  0.  0.\n",
      " 0.  0.  4.  3.  0.  0.  0.  5.  0.  0.  5.  0.  0.  4.  0.  0.  0.  0.\n",
      " 0.  4.  4.  0.  3.  2.5 4.  0.  4.  3.  4.  2.5 4.  2.5 3.  5. ]\n"
     ]
    }
   ],
   "source": [
    "#we need to form 2 2-d arrays. one is output rating array and one is array R where Rij = 1 if rating is there else Rij = 0\n",
    "y_actual = np.zeros((no_of_movies,no_of_users))\n",
    "rating_array = np.zeros((no_of_movies,no_of_users))\n",
    "for index,row in rating_dataset_cleaned.iterrows():\n",
    "    movie_index = int(row['movieIndex'])\n",
    "    user_index = int(row['userId']) - 1\n",
    "    rating_array[movie_index,user_index] = 1\n",
    "    y_actual[movie_index,user_index] = row['rating']\n",
    "print(y_actual[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "926f7d24-465d-45b4-94e4-76e82599444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape is  (9724, 610)\n",
      "R shape is  (9724, 610)\n",
      "w shape is  (611, 10)\n",
      "X shape is  (9724, 10)\n"
     ]
    }
   ],
   "source": [
    "#we have our output values ready\n",
    "# now we need our X and w matrices. X matrix shape should be no_of_movies x features and w should be no_of_users x features so when x and wt are\n",
    "# multiplied we get y as no_of_movies x no_of_users which is our y. lets take 10 features\n",
    "# w = np.random.randn(no_of_users+1, 10) * 0.01\n",
    "# X = np.random.randn(no_of_movies,10) * 0.01\n",
    "# b = np.zeros((no_of_movies, 1))\n",
    "\n",
    "w = tf.Variable(np.random.randn(no_of_users + 1, 10) * 0.01, dtype=tf.float32)\n",
    "X = tf.Variable(np.random.randn(no_of_movies, 10) * 0.01, dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((no_of_movies, 1)), dtype=tf.float32)\n",
    "\n",
    "#lets print all shapes to verify if we are correct\n",
    "print(\"Y shape is \", y_actual.shape)\n",
    "print(\"R shape is \", rating_array.shape)\n",
    "print(\"w shape is \", w.shape)\n",
    "print(\"X shape is \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c6ae8008-aabb-418a-a16f-3cb38e9094a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cost(X, W, b, Y, R, lambda_):\n",
    "#     y_pred = X @ W.T + b  \n",
    "#     error = (y_pred - Y) * R \n",
    "#     J = 0.5 * np.sum(error ** 2) \n",
    "#     J += 0.5 * lambda_ * (np.sum(W ** 2) + np.sum(X ** 2))\n",
    "#     return J\n",
    "\n",
    "def compute_cost(X, W, b, Y, R, lambda_):\n",
    "    y_pred = tf.matmul(X, tf.transpose(W)) + b\n",
    "    error = (y_pred - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(tf.square(error))\n",
    "    J += 0.5 * lambda_ * (tf.reduce_sum(tf.square(W)) + tf.reduce_sum(tf.square(X)))\n",
    "    return J  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6dd6a7af-f392-4990-868f-7f8ce78afe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8989 6961 6725  167 7679  685  676 1367 6834 5772 4960 6019 8277 3659\n",
      " 3702 8782 1815 2621  789 3534 8648 1448  499 6914 2186 8432  706 6180\n",
      "  261 5115]\n",
      "      movieId                                              title  movieIndex\n",
      "8989   140133                  Hollywood Chainsaw Hookers (1988)        8989\n",
      "6961    66544                                   Nuremberg (2000)        6961\n",
      "6725    59306                                  Prom Night (2008)        6725\n",
      "167       198                                Strange Days (1995)         167\n",
      "7679    89774                                     Warrior (2011)        7679\n",
      "685       903                                     Vertigo (1958)         685\n",
      "676       892                               Twelfth Night (1996)         676\n",
      "1367     1870                       Dancer, Texas Pop. 81 (1998)        1367\n",
      "6834    62008                                   Dead Fury (2008)        6834\n",
      "5772    31545     Trou, Le (Hole, The) (Night Watch, The) (1960)        5772\n",
      "4960     7579                         Pride and Prejudice (1940)        4960\n",
      "6019    39427                                        Stay (2005)        6019\n",
      "8277   106487             The Hunger Games: Catching Fire (2013)        8277\n",
      "3659     5046                                    Impostor (2002)        3659\n",
      "3702     5112                                 Last Orders (2001)        3702\n",
      "8782   130450                                         Pan (2015)        8782\n",
      "1815     2416                              Back to School (1986)        1815\n",
      "2621     3511                             Ready to Rumble (2000)        2621\n",
      "789      1032                         Alice in Wonderland (1951)         789\n",
      "3534     4840         Last Metro, The (Dernier métro, Le) (1980)        3534\n",
      "8648   121231                                  It Follows (2014)        8648\n",
      "1448     1972  Nightmare on Elm Street 5: The Dream Child, A ...        1448\n",
      "499       579                    Escort, The (Scorta, La) (1993)         499\n",
      "6914    64993  5 Centimeters per Second (Byôsoku 5 senchimêto...        6914\n",
      "2186     2905                   Sanjuro (Tsubaki Sanjûrô) (1962)        2186\n",
      "8432   112171                              Equalizer, The (2014)        8432\n",
      "706       924                       2001: A Space Odyssey (1968)         706\n",
      "6180    45175                                 Kinky Boots (2005)        6180\n",
      "261       301                  Picture Bride (Bijo photo) (1994)         261\n",
      "5115     8189                         Zazie dans le métro (1960)        5115\n"
     ]
    }
   ],
   "source": [
    "#now lets add our ratings. we need to increase no of users by 1 which indicate us\n",
    "random_movies_indices = np.random.choice(no_of_movies, 30, replace=False)\n",
    "print(random_movies_indices)\n",
    "random_movies_selected = movies_dataset_refined.loc[random_movies_indices,:]\n",
    "print(random_movies_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd6e43c7-9ef5-487c-bb40-c5e3a6b28ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(no_of_movies)\n",
    "# random_ratings = np.random.randint(1,5,30)\n",
    "# for i, (_, movie) in enumerate(random_movies_selected.iterrows()):\n",
    "#     movie_index = movie['movieIndex']\n",
    "#     my_ratings[movie_index] = random_ratings[i]\n",
    "my_ratings[1] = 4\n",
    "my_ratings[6182] = 3\n",
    "my_ratings[6191] = 4\n",
    "my_ratings[6234] = 3.5\n",
    "my_ratings[6241] = 4.5\n",
    "my_ratings[6248] = 4\n",
    "my_ratings[6299] = 3.5\n",
    "my_ratings[6314] = 4.5\n",
    "my_ratings[6364] = 2.5\n",
    "my_ratings[6450] = 3.5\n",
    "my_ratings[6693] = 5\n",
    "my_ratings[6729] = 3.5\n",
    "my_ratings[6736] = 4.5\n",
    "my_ratings[6743] = 4\n",
    "my_ratings[6975] = 2.5\n",
    "my_ratings[7069] = 3\n",
    "my_ratings[7114] = 3.5\n",
    "my_ratings[7226] = 5\n",
    "my_ratings[7241] = 4.5\n",
    "my_ratings[7305] = 1.5\n",
    "my_ratings[7396] = 3.5\n",
    "my_ratings[7637] = 4.5\n",
    "my_ratings[7650] = 2.5\n",
    "my_ratings[7707] = 3.5\n",
    "my_ratings[7750] = 3\n",
    "my_ratings[7756] = 2.5\n",
    "my_ratings[7827] = 3.5\n",
    "my_ratings[7937] = 2.5\n",
    "my_ratings[8008] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "461473fb-5308-46c5-8a22-1f461878f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 611)\n"
     ]
    }
   ],
   "source": [
    "y_actual = np.c_[my_ratings, y_actual]\n",
    "print(y_actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bbe99f0f-d7da-44fa-95d4-52cacd215eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 611)\n"
     ]
    }
   ],
   "source": [
    "my_rating_exists_array = (my_ratings > 0).astype(int)\n",
    "rating_array = np.c_[my_rating_exists_array,rating_array]\n",
    "print(rating_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d98ef-98a3-40e8-ba30-4e0dc7627ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0b87249a-32c4-4ce4-8756-06a2723fc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the rating by calc mean rating for every movie\n",
    "def normalize_function(Y,R):\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return Ynorm, Ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5af11ab8-9c9b-4d51-bb80-23166616d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual_normalized, y_mean = normalize_function(y_actual,rating_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d8b19690-46fa-4b8a-86e3-eea896098730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 38714.8555\n",
      "Training loss at iteration 20: 36813.4414\n",
      "Training loss at iteration 40: 28291.2383\n",
      "Training loss at iteration 60: 21443.2695\n",
      "Training loss at iteration 80: 17429.1465\n",
      "Training loss at iteration 100: 15446.8965\n",
      "Training loss at iteration 120: 14386.3916\n",
      "Training loss at iteration 140: 13751.6729\n",
      "Training loss at iteration 160: 13330.2559\n",
      "Training loss at iteration 180: 13030.6924\n",
      "Training loss at iteration 200: 12807.4414\n",
      "Training loss at iteration 220: 12635.0977\n",
      "Training loss at iteration 240: 12498.5879\n",
      "Training loss at iteration 260: 12387.9365\n",
      "Training loss at iteration 280: 12296.7275\n",
      "Training loss at iteration 300: 12220.4043\n",
      "Training loss at iteration 320: 12155.7676\n",
      "Training loss at iteration 340: 12100.4844\n",
      "Training loss at iteration 360: 12052.7539\n",
      "Training loss at iteration 380: 12011.1582\n",
      "Training loss at iteration 400: 11974.5859\n",
      "Training loss at iteration 420: 11942.2236\n",
      "Training loss at iteration 440: 11913.3809\n",
      "Training loss at iteration 460: 11887.4922\n",
      "Training loss at iteration 480: 11864.1182\n",
      "Training loss at iteration 500: 11842.8750\n",
      "Training loss at iteration 520: 11823.4902\n",
      "Training loss at iteration 540: 11805.6816\n",
      "Training loss at iteration 560: 11789.2568\n",
      "Training loss at iteration 580: 11774.0449\n",
      "Training loss at iteration 600: 11759.8877\n",
      "Training loss at iteration 620: 11746.6826\n",
      "Training loss at iteration 640: 11734.3164\n",
      "Training loss at iteration 660: 11722.7207\n",
      "Training loss at iteration 680: 11711.8076\n",
      "Training loss at iteration 700: 11701.4941\n",
      "Training loss at iteration 720: 11691.7412\n",
      "Training loss at iteration 740: 11682.4883\n",
      "Training loss at iteration 760: 11673.6973\n",
      "Training loss at iteration 780: 11665.3203\n",
      "Training loss at iteration 800: 11657.3359\n",
      "Training loss at iteration 820: 11649.7070\n",
      "Training loss at iteration 840: 11642.4131\n",
      "Training loss at iteration 860: 11635.4297\n",
      "Training loss at iteration 880: 11628.7363\n",
      "Training loss at iteration 900: 11622.3125\n",
      "Training loss at iteration 920: 11616.1484\n",
      "Training loss at iteration 940: 11610.2227\n",
      "Training loss at iteration 960: 11604.5156\n",
      "Training loss at iteration 980: 11599.0215\n",
      "Training loss at iteration 1000: 11593.7324\n",
      "Training loss at iteration 1020: 11588.6309\n",
      "Training loss at iteration 1040: 11583.7051\n",
      "Training loss at iteration 1060: 11578.9512\n",
      "Training loss at iteration 1080: 11574.3643\n",
      "Training loss at iteration 1100: 11569.9238\n",
      "Training loss at iteration 1120: 11565.6318\n",
      "Training loss at iteration 1140: 11561.4775\n",
      "Training loss at iteration 1160: 11557.4512\n",
      "Training loss at iteration 1180: 11553.5449\n",
      "Training loss at iteration 1200: 11549.7539\n",
      "Training loss at iteration 1220: 11546.0771\n",
      "Training loss at iteration 1240: 11542.5020\n",
      "Training loss at iteration 1260: 11539.0264\n",
      "Training loss at iteration 1280: 11535.6514\n",
      "Training loss at iteration 1300: 11532.3662\n",
      "Training loss at iteration 1320: 11529.1787\n",
      "Training loss at iteration 1340: 11526.0771\n",
      "Training loss at iteration 1360: 11523.0674\n",
      "Training loss at iteration 1380: 11520.1436\n",
      "Training loss at iteration 1400: 11517.3008\n",
      "Training loss at iteration 1420: 11514.5391\n",
      "Training loss at iteration 1440: 11511.8516\n",
      "Training loss at iteration 1460: 11509.2363\n",
      "Training loss at iteration 1480: 11506.6924\n"
     ]
    }
   ],
   "source": [
    "# iterations = 1500\n",
    "# lambda_ = 0.1\n",
    "# learning_rate = 0.01\n",
    "# for iter in range(iterations):\n",
    "#     print(iter)\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         cost_value = compute_cost(X, w, b, y_actual_normalized, rating_array, lambda_)\n",
    "#     grads = tape.gradient( cost_value, [X,w,b] )\n",
    "#     dX, dW, db = grads\n",
    "#     X.assign_sub(learning_rate * dX)\n",
    "#     w.assign_sub(learning_rate * dW)\n",
    "#     b.assign_sub(learning_rate * db)\n",
    "#     if iter % 20 == 0:\n",
    "#         print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "iterations = 1500 \n",
    "lambda_ = 0.1      \n",
    "learning_rate = 0.01  \n",
    "min_delta = 1e-6\n",
    "previous_loss = float('inf')\n",
    "\n",
    "for iter in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = compute_cost(X, w, b, y_actual_normalized, rating_array, lambda_)\n",
    "\n",
    "    grads = tape.gradient(cost_value, [X, w, b])    \n",
    "    grads = [tf.clip_by_value(g, -1.0, 1.0) for g in grads]  \n",
    "    dX, dW, db = grads\n",
    "    X.assign_sub(learning_rate * dX)\n",
    "    w.assign_sub(learning_rate * dW)\n",
    "    b.assign_sub(learning_rate * db)\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value.numpy():.4f}\")    \n",
    "    if abs(previous_loss - cost_value.numpy()) < min_delta:\n",
    "        print(f\"Stopping early at iteration {iter}. Loss stabilized at {cost_value.numpy():.4f}\")\n",
    "        break\n",
    "\n",
    "    previous_loss = cost_value.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf0e5415-fc54-48e1-9cd4-80c3b3bc8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the last user:\n",
      "5.561789\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.matmul(X, tf.transpose(w)) + b \n",
    "y_pred_array = y_pred.numpy()\n",
    "y_pred_array += y_mean\n",
    "print(\"Predictions for the last user:\")\n",
    "print(y_pred_array[52,0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "694155cd-47a6-4b4e-a8e5-66fc7b9a9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs Predicted Ratings:\n",
      "(9724, 611)\n",
      "Movie Index 1: Actual = 4.0, Predicted = 4.08\n",
      "Movie Index 6182: Actual = 3.0, Predicted = 3.11\n",
      "Movie Index 6191: Actual = 4.0, Predicted = 3.66\n",
      "Movie Index 6234: Actual = 3.5, Predicted = 3.45\n",
      "Movie Index 6241: Actual = 4.5, Predicted = 4.55\n",
      "Movie Index 6248: Actual = 4.0, Predicted = 3.99\n",
      "Movie Index 6299: Actual = 3.5, Predicted = 3.50\n",
      "Movie Index 6314: Actual = 4.5, Predicted = 4.47\n",
      "Movie Index 6364: Actual = 2.5, Predicted = 2.49\n",
      "Movie Index 6450: Actual = 3.5, Predicted = 3.49\n",
      "Movie Index 6693: Actual = 5.0, Predicted = 4.38\n",
      "Movie Index 6729: Actual = 3.5, Predicted = 3.69\n",
      "Movie Index 6736: Actual = 4.5, Predicted = 4.50\n",
      "Movie Index 6743: Actual = 4.0, Predicted = 3.61\n",
      "Movie Index 6975: Actual = 2.5, Predicted = 2.69\n",
      "Movie Index 7069: Actual = 3.0, Predicted = 2.99\n",
      "Movie Index 7114: Actual = 3.5, Predicted = 3.49\n",
      "Movie Index 7226: Actual = 5.0, Predicted = 4.99\n",
      "Movie Index 7241: Actual = 4.5, Predicted = 4.04\n",
      "Movie Index 7305: Actual = 1.5, Predicted = 1.50\n",
      "Movie Index 7396: Actual = 3.5, Predicted = 3.96\n",
      "Movie Index 7637: Actual = 4.5, Predicted = 4.42\n",
      "Movie Index 7650: Actual = 2.5, Predicted = 2.52\n",
      "Movie Index 7707: Actual = 3.5, Predicted = 3.48\n",
      "Movie Index 7750: Actual = 3.0, Predicted = 3.64\n",
      "Movie Index 7756: Actual = 2.5, Predicted = 2.50\n",
      "Movie Index 7827: Actual = 3.5, Predicted = 3.23\n",
      "Movie Index 7937: Actual = 2.5, Predicted = 2.84\n",
      "Movie Index 8008: Actual = 3.0, Predicted = 3.16\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual vs Predicted Ratings:\")\n",
    "print(y_pred_array.shape)\n",
    "for i, rating in enumerate(my_ratings):\n",
    "    if rating > 0:\n",
    "        print(f\"Movie Index {i}: Actual = {rating}, Predicted = {y_pred_array[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085305e-4e6b-4d83-ad84-2e075ecc949b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6dd5d-7511-41d6-b432-8958f8ad0f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
